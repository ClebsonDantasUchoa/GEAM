{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resoluçao do problema: https://www.codenation.com.br/journey/data-science/challenge/enem-4.html\n",
    "\n",
    "## Definição: \n",
    "Neste desafio deverá descobrir quais estudantes estão fazendo a prova apenas para treino.\n",
    "\n",
    "Alguns estudantes decidem realizar prova do ENEM de forma precoce, como um teste (coluna IN_TREINEIRO). Neste desafio, você deve criar um modelo de classificação binária para inferir a mesma. Os resultados possíveis da sua resposta devem ser “0” ou “1”.\n",
    "\n",
    "Salve sua resposta em um arquivo chamado answer.csv com duas colunas: NU_INSCRICAO e IN_TREINEIRO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leitura do arquivo de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\n",
    "    'NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO','TP_ST_CONCLUSAO','IN_TREINEIRO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados após a filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_NOTA_CN</th>\n",
       "      <th>NU_NOTA_CH</th>\n",
       "      <th>NU_NOTA_LC</th>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>IN_TREINEIRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436.3</td>\n",
       "      <td>495.4</td>\n",
       "      <td>581.2</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474.5</td>\n",
       "      <td>544.1</td>\n",
       "      <td>599.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_NOTA_CN  NU_NOTA_CH  NU_NOTA_LC  NU_NOTA_REDACAO  TP_ST_CONCLUSAO  \\\n",
       "0       436.3       495.4       581.2            520.0                1   \n",
       "1       474.5       544.1       599.0            580.0                2   \n",
       "2         NaN         NaN         NaN              NaN                3   \n",
       "3         NaN         NaN         NaN              NaN                1   \n",
       "4         NaN         NaN         NaN              NaN                1   \n",
       "\n",
       "   IN_TREINEIRO  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU_NOTA_CN         3389\n",
      "NU_NOTA_CH         3389\n",
      "NU_NOTA_LC         3597\n",
      "NU_NOTA_REDACAO    3597\n",
      "TP_ST_CONCLUSAO       0\n",
      "IN_TREINEIRO          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU_NOTA_CN         0\n",
      "NU_NOTA_CH         0\n",
      "NU_NOTA_LC         0\n",
      "NU_NOTA_REDACAO    0\n",
      "TP_ST_CONCLUSAO    0\n",
      "IN_TREINEIRO       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados de treino entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.values[:, :-1]\n",
    "y = train.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "    test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e avaliçao dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.96      0.97      3588\n",
      "        1.0       0.78      0.85      0.81       531\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4119\n",
      "\n",
      "accuracy: \n",
      "0.9497450837581938\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "resposta_dt = dt.predict(X_test)\n",
    "print(metrics.classification_report(y_test, resposta_dt))\n",
    "accuracy_dt = metrics.accuracy_score(y_test, resposta_dt)\n",
    "print('accuracy: ')\n",
    "print(accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.95      0.91      3588\n",
      "        1.0       0.33      0.18      0.23       531\n",
      "\n",
      "avg / total       0.81      0.85      0.83      4119\n",
      "\n",
      "accuracy: \n",
      "0.8468074775430929\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "resposta_lr = lr.predict(X_test)\n",
    "print(metrics.classification_report(y_test, resposta_lr))\n",
    "accuracy_lr = metrics.accuracy_score(y_test, resposta_lr);\n",
    "print('accuracy: ')\n",
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.99      0.93      3588\n",
      "        1.0       0.61      0.14      0.23       531\n",
      "\n",
      "avg / total       0.85      0.88      0.84      4119\n",
      "\n",
      "accuracy: \n",
      "0.8778829813061423\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "resposta_svc = svc.predict(X_test)\n",
    "print(metrics.classification_report(y_test, resposta_svc))\n",
    "accuracy_svc = metrics.accuracy_score(y_test, resposta_svc);\n",
    "print('accuracy: ')\n",
    "print(accuracy_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.97      0.93      3588\n",
      "        1.0       0.46      0.17      0.25       531\n",
      "\n",
      "avg / total       0.83      0.87      0.84      4119\n",
      "\n",
      "accuracy: \n",
      "0.8676863316338917\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "resposta_knn = knn.predict(X_test)\n",
    "print(metrics.classification_report(y_test, resposta_knn))\n",
    "accuracy_knn = metrics.accuracy_score(y_test, resposta_knn);\n",
    "print('accuracy: ')\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GGradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e161429c1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodeloGBC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodeloGBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresposta_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeloGBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresposta_gbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresposta_gbc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GGradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "modeloGBC = GGradientBoostingClassifier()\n",
    "modeloGBC.fit(X_train, y_train)\n",
    "resposta_gbc = modeloGBC.predict(X_test)\n",
    "print(metrics.classification_report(y_test, resposta_gbc))\n",
    "accuracy_gbc = metrics.accuracy_score(y_test, resposta_gbc);\n",
    "print('accuracy: ')\n",
    "print(accuracy_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacao = pd.DataFrame(data=[[\n",
    "    accuracy_dt, accuracy_lr, accuracy_svc, accuracy_knn, accuracy_gbc]],\n",
    "    columns=['DT', 'LR', 'SVC', 'KNN', 'GBC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacao = comparacao.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacao.plot(kind='bar', grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo escolhido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['NU_NOTA_CN','NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'TP_ST_CONCLUSAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## realizando a predição com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitivo = tree.DecisionTreeClassifier()\n",
    "definitivo.fit(X, y)\n",
    "resposta_definitivo = definitivo.predict(test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = pd.read_csv('test.csv')['NU_INSCRICAO']\n",
    "answer['IN_TREINEIRO'] = resposta_definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Após submeter o arquivo 'answer.csv' para a codenation, foi obtida a pontuação de 95%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
